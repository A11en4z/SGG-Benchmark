{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-08 14:49:59.841\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msgg_benchmark.utils.logger\u001b[0m:\u001b[36msetup_logger\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mUsing loguru logger with level: INFO\u001b[0m\n",
      "Overriding model.yaml nc=80 with nc=84\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3824332  ultralytics.nn.modules.head.Detect           [84, [192, 384, 576]]         \n",
      "YOLOv8m summary: 295 layers, 25904956 parameters, 25904940 gradients, 79.3 GFLOPs\n",
      "\n",
      "loading word vectors from /home/maelic/glove/glove.6B.200d.pt\n",
      "loading word vectors from /home/maelic/glove/glove.6B.200d.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-04-08 14:50:03 971178:971178 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-04-08 14:50:03 971178:971178 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-04-08 14:50:03 971178:971178 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.03668403625488281\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        22.91%       8.924ms        94.37%      36.761ms      36.761ms       0.000us         0.00%      22.400ms      22.400ms             1  \n",
      "                                           aten::conv2d         1.04%     405.000us        16.65%       6.488ms      72.899us       0.000us         0.00%       8.954ms     100.607us            89  \n",
      "                                      aten::convolution         1.48%     576.000us        15.87%       6.181ms      69.449us       0.000us         0.00%       8.947ms     100.528us            89  \n",
      "                                     aten::_convolution         1.32%     516.000us        14.86%       5.787ms      65.022us       0.000us         0.00%       9.249ms     103.921us            89  \n",
      "                                aten::cudnn_convolution         9.19%       3.579ms        13.16%       5.125ms      57.584us       9.014ms        40.24%       9.014ms     101.281us            89  \n",
      "                                           aten::linear         0.30%     115.000us        13.00%       5.065ms     148.971us       0.000us         0.00%       9.533ms     280.382us            34  \n",
      "                                            aten::addmm        11.34%       4.416ms        12.23%       4.765ms     140.147us       9.533ms        42.56%       9.533ms     280.382us            34  \n",
      "                                       aten::batch_norm         0.69%     270.000us        11.32%       4.409ms      54.432us       0.000us         0.00%     911.000us      11.247us            81  \n",
      "                           aten::_batch_norm_impl_index         0.75%     291.000us        10.84%       4.222ms      52.123us       0.000us         0.00%     830.000us      10.247us            81  \n",
      "                                 aten::cudnn_batch_norm         4.75%       1.849ms         9.96%       3.879ms      49.101us     928.000us         4.14%     928.000us      11.747us            79  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 38.956ms\n",
      "Self CUDA time total: 22.400ms\n",
      "\n",
      "<torch.profiler.profiler.profile object at 0x7fd3edfca350>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from demo_model import SGG_Model\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "config_path = \"../checkpoints/INDOORVG4/SGDET/penet-yolov8m/config.yaml\"\n",
    "dict_path = \"../datasets/IndoorVG_4/VG-SGG-dicts.json\"\n",
    "\n",
    "example_img = \"./example.jpg\"\n",
    "# load image with cv2\n",
    "img = cv2.imread(example_img)\n",
    "\n",
    "model = SGG_Model(config_path, dict_path)\n",
    "img_list, target = model._pre_processing(img)\n",
    "targets = [target.to(model.device)]\n",
    "img_list = img_list.to(model.device)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        time_start = time.time()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs, features = model.model.backbone(img_list.tensors, embed=True)\n",
    "            proposals = model.model.backbone.postprocess(outputs, img_list.image_sizes)\n",
    "\n",
    "            _, predictions, _ = model.model.roi_heads(features, proposals, targets, None, proposals)\n",
    "\n",
    "        time_end = time.time()\n",
    "print(f\"Time: {time_end - time_start}\")\n",
    "#predictions = model._post_process_yolo(predictions[0], orig_size=img_list.image_sizes[0])\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
