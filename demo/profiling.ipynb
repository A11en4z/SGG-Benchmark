{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-08 14:58:36.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msgg_benchmark.utils.logger\u001b[0m:\u001b[36msetup_logger\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mUsing loguru logger with level: INFO\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=84\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3824332  ultralytics.nn.modules.head.Detect           [84, [192, 384, 576]]         \n",
      "YOLOv8m summary: 295 layers, 25904956 parameters, 25904940 gradients, 79.3 GFLOPs\n",
      "\n",
      "loading word vectors from /home/maelic/glove/glove.6B.200d.pt\n",
      "loading word vectors from /home/maelic/glove/glove.6B.200d.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-04-08 14:58:39 971178:971178 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n",
      "STAGE:2024-04-08 14:58:39 971178:971178 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-04-08 14:58:39 971178:971178 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 0.02965402603149414\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference        20.51%       6.877ms        88.72%      29.744ms      29.744ms       0.000us         0.00%      22.369ms      22.369ms             1  \n",
      "                                           aten::conv2d         1.05%     351.000us        15.18%       5.088ms      57.169us       0.000us         0.00%       8.527ms      95.809us            89  \n",
      "                                      aten::convolution         1.32%     442.000us        14.40%       4.829ms      54.258us       0.000us         0.00%       8.992ms     101.034us            89  \n",
      "                                     aten::_convolution         1.31%     440.000us        13.42%       4.499ms      50.551us       0.000us         0.00%       9.122ms     102.494us            89  \n",
      "                                aten::cudnn_convolution         8.33%       2.794ms        11.87%       3.978ms      44.697us       8.971ms        40.10%       8.971ms     100.798us            89  \n",
      "                                  cudaDeviceSynchronize        11.28%       3.783ms        11.28%       3.783ms       3.783ms       0.000us         0.00%       0.000us       0.000us             1  \n",
      "                                           aten::linear         0.58%     194.000us        11.05%       3.704ms     108.941us       0.000us         0.00%       9.380ms     275.882us            34  \n",
      "                                            aten::addmm         9.67%       3.241ms        10.36%       3.473ms     102.147us       9.506ms        42.50%       9.506ms     279.588us            34  \n",
      "                                       aten::batch_norm         0.32%     107.000us        10.25%       3.435ms      42.407us       0.000us         0.00%     945.000us      11.667us            81  \n",
      "                           aten::_batch_norm_impl_index         0.74%     247.000us         9.82%       3.293ms      40.654us       0.000us         0.00%     838.000us      10.346us            81  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 33.527ms\n",
      "Self CUDA time total: 22.369ms\n",
      "\n",
      "Number of parameters: 171628072\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from demo_model import SGG_Model\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "config_path = \"/home/maelic/ros2_humble/src/Robots-Scene-Understanding/rsu_scene_graph_generation/models/penet-yolov8m/config.yaml\"\n",
    "dict_path = \"../datasets/IndoorVG_4/VG-SGG-dicts.json\"\n",
    "\n",
    "example_img = \"./example.jpg\"\n",
    "# load image with cv2\n",
    "img = cv2.imread(example_img)\n",
    "\n",
    "model = SGG_Model(config_path, dict_path)\n",
    "img_list, target = model._pre_processing(img)\n",
    "targets = [target.to(model.device)]\n",
    "img_list = img_list.to(model.device)\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        time_start = time.time()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            outputs, features = model.model.backbone(img_list.tensors, embed=True)\n",
    "            proposals = model.model.backbone.postprocess(outputs, img_list.image_sizes)\n",
    "\n",
    "            _, predictions, _ = model.model.roi_heads(features, proposals, targets, None, proposals)\n",
    "\n",
    "        time_end = time.time()\n",
    "print(f\"Time: {time_end - time_start}\")\n",
    "#predictions = model._post_process_yolo(predictions[0], orig_size=img_list.image_sizes[0])\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
    "\n",
    "total_params = sum(p.numel() for p in model.model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of full model: 171628072\n",
      "Number of parameters of backbone: 25904956\n",
      "Number of parameters of Relation head: 145723116\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.model.parameters())\n",
    "print(f\"Number of parameters of full model: {total_params}\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.model.backbone.parameters())\n",
    "print(f\"Number of parameters of backbone: {total_params}\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.model.roi_heads.parameters())\n",
    "print(f\"Number of parameters of Relation head: {total_params}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
