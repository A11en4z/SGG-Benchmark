{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from sgg_benchmark.config import cfg\n",
    "from sgg_benchmark.modeling.detector import build_detection_model\n",
    "from sgg_benchmark.utils.checkpoint import DetectronCheckpointer\n",
    "from sgg_benchmark.data import make_data_loader\n",
    "from sgg_benchmark.structures.image_list import to_image_list\n",
    "\n",
    "def latency_bench(config_file):\n",
    "    cfg.merge_from_file(config_file)\n",
    "    cfg.MODEL.BACKBONE.NMS_THRESH = 0.001\n",
    "    cfg.MODEL.ROI_HEADS.DETECTIONS_PER_IMG = 80\n",
    "    cfg.TEST.IMS_PER_BATCH = 1\n",
    "    # cfg.freeze()\n",
    "\n",
    "    # build dataloader\n",
    "    val_data_loader = make_data_loader(\n",
    "        cfg,\n",
    "        mode='val',\n",
    "        is_distributed=False,\n",
    "    )\n",
    "    val_data_loader = val_data_loader[0]\n",
    "\n",
    "    cfg.TEST.CUSTUM_EVAL = True\n",
    "\n",
    "    model = build_detection_model(cfg)\n",
    "    checkpointer = DetectronCheckpointer(cfg, model, save_dir=cfg.OUTPUT_DIR)\n",
    "    last_check = checkpointer.get_checkpoint_file()\n",
    "    if last_check == \"\":\n",
    "        last_check = cfg.MODEL.WEIGHT\n",
    "    print(\"Loading last checkpoint from {}...\".format(last_check))\n",
    "    _ = checkpointer.load(last_check)\n",
    "\n",
    "    model.to(cfg.MODEL.DEVICE)\n",
    "    model.roi_heads.eval()\n",
    "    model.backbone.eval()\n",
    "\n",
    "    # INIT LOGGERS\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    repetitions = 100\n",
    "    timings = np.zeros((repetitions,1))\n",
    "    timings_relation_head = np.zeros((repetitions,1))\n",
    "    input_img, _, _ = next(iter(val_data_loader))\n",
    "    input_img = input_img.to(cfg.MODEL.DEVICE)\n",
    "\n",
    "    #GPU-WARM-UP\n",
    "    for _ in tqdm(range(10)):\n",
    "        _ = model(input_img, None)\n",
    "    # MEASURE PERFORMANCE\n",
    "    with torch.no_grad():\n",
    "        for rep, (input_img, _, _) in enumerate(tqdm(val_data_loader)):\n",
    "            if rep == repetitions:\n",
    "                break\n",
    "            input_img = input_img.to(cfg.MODEL.DEVICE)\n",
    "            images = to_image_list(input_img)\n",
    "            starter.record()\n",
    "            outputs, features = model.backbone(images.tensors, embed=True)\n",
    "            proposals = model.backbone.postprocess(outputs, images.image_sizes)\n",
    "            ender.record()\n",
    "            # WAIT FOR GPU SYNC\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings[rep] = curr_time\n",
    "\n",
    "            starter.record()\n",
    "            _, _, _ = model.roi_heads(features, proposals, None, None, proposals)\n",
    "            ender.record()\n",
    "            # WAIT FOR GPU SYNC\n",
    "            torch.cuda.synchronize()\n",
    "            curr_time = starter.elapsed_time(ender)\n",
    "            timings_relation_head[rep] = curr_time\n",
    "\n",
    "    mean_syn = np.sum(timings) / repetitions\n",
    "    mean_syn_relation_head = np.sum(timings_relation_head) / repetitions\n",
    "    std_syn = np.std(timings)\n",
    "    print(\"Average time backbone: {} ms\".format(mean_syn))\n",
    "    print(\"Average time relation head: {} ms\".format(mean_syn_relation_head))\n",
    "    print(\"Full network latency: {} ms\".format(mean_syn + mean_syn_relation_head))\n",
    "    print(\"Standard deviation: {} ms\".format(std_syn))\n",
    "\n",
    "    # print total number of params\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Total number of parameters: {total_params}\")\n",
    "\n",
    "conf = \"/home/maelic/Documents/PhD/MyModel/SGG-Benchmark/checkpoints/IndoorVG4/SGDET/penet-yolov8m/config.yml\"\n",
    "\n",
    "latency_bench(conf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
